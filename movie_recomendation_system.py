# -*- coding: utf-8 -*-
"""Movie Recomendation system.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nwtETvMk8cHS7f9CtLHv3sMSt14yEqe1
"""

import numpy as np
import pandas as pd
import ast
import nltk
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Read data
film = pd.read_csv("tmdb_5000_movies.csv")
credits = pd.read_csv("tmdb_5000_credits.csv")

movie = film.merge(credits, on="title")

movie = movie[['id', 'title', 'overview', 'genres', 'keywords', 'popularity', 'vote_average', 'vote_count', 'cast', 'crew', 'production_companies', 'release_date', 'original_language', 'revenue', 'runtime']]

movie.dropna(inplace=True)

# Clean keywords, genres, and production_companies
def cleantitle(obj):
    Title = []
    for i in ast.literal_eval(obj):
        Title.append(i['name'])
    return Title

movie['keywords'] = movie['keywords'].apply(cleantitle)
movie['genres'] = movie['genres'].apply(cleantitle)
movie['production_companies'] = movie['production_companies'].apply(cleantitle)

# Extract directors from crew
def extractdirectors(data):
    directors = []
    for item in ast.literal_eval(data):
        if 'job' in item and item['job'] == 'Director':
            directors.append(item['name'])
    return directors

movie['crew'] = movie['crew'].apply(extractdirectors)

# Tokenize and clean text data
movie['overview'] = movie['overview'].apply(lambda x: x.split())

# Remove spaces
def remove_spaces(lst):
    return [i.replace(" ", "") for i in lst]

movie['genres'] = movie['genres'].apply(remove_spaces)
movie['cast'] = movie['cast'].apply(remove_spaces)
movie['crew'] = movie['crew'].apply(remove_spaces)
movie['production_companies'] = movie['production_companies'].apply(remove_spaces)

# Combine text attributes into 'tags'
movie['tags'] = movie['overview'] + movie['genres'] + movie['cast'] + movie['crew'] + movie['production_companies']

movie['tags'] = movie['tags'].apply(lambda x: " ".join(x))


nltk.download('punkt')
ps = PorterStemmer()

# Apply stemming to 'tags'
def stem(text):
    y = []
    for i in text.split():
        y.append(ps.stem(i))
    return " ".join(y)

main_df = movie[['id', 'title', 'tags']]  # Updated columns in main_df

main_df['tags'] = main_df['tags'].apply(stem)

cv = CountVectorizer(max_features=5000, stop_words='english')

vector = cv.fit_transform(main_df['tags']).toarray()

cosine_sim_vector = cosine_similarity(vector)

# Recommendation function
def recommend(movie_title):
    index = main_df[main_df['title'] == movie_title].index[0]
    distances = sorted(list(enumerate(cosine_sim_vector[index])), reverse=True, key=lambda x: x[1])
    recommended_movies = [main_df.iloc[i[0]]['title'] for i in distances[1:6]]
    return recommended_movies

# Usage example:
recommended_movies = recommend('Harry Potter and the Half-Blood Prince')
print("Recommended Movies:")
for movie in recommended_movies:
    print(movie)